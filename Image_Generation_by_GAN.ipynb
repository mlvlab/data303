{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJoHa9e/DRK4frD3sFHv1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlvlab/data303/blob/main/Image_Generation_by_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCGAN Training Tutorials\n"
      ],
      "metadata": {
        "id": "wNFH4tFkK60T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Settings"
      ],
      "metadata": {
        "id": "vyDpEtAqK_aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 1.1 Import required library"
      ],
      "metadata": {
        "id": "fAgp-MN9LByu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WUEWZKQtK554"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vtils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 1.2 Set seed for reproducibility\n"
      ],
      "metadata": {
        "id": "l-Oaq6d0LGmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4RWJZURLGAx",
        "outputId": "806b444b-bfb4-489c-a3a4-fa82cbbf80c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prepare Datasets\n"
      ],
      "metadata": {
        "id": "EmL_NMHeLLs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "image_size = 64\n",
        "batch_size = 100\n",
        "\n",
        "# Data preprocesssing\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Data loader\n",
        "train_dataset = dset.MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = dset.MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "GTAnUvpALNVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define Models for Generator and Discriminator\n"
      ],
      "metadata": {
        "id": "NcTXUbJ0LPWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.1 Define Generator and Discriminator Class\n"
      ],
      "metadata": {
        "id": "HkuLdySyLSJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim = 100, channel_dim=128, output_dim=1):\n",
        "        super(Generator, self).__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(latent_dim, channel_dim*8, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(channel_dim*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(channel_dim*8, channel_dim*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(channel_dim*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(channel_dim*4, channel_dim*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(channel_dim*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(channel_dim*2, channel_dim, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(channel_dim)\n",
        "        self.deconv5 = nn.ConvTranspose2d(channel_dim, output_dim, 4, 2, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel_dim=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, channel_dim, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(channel_dim, channel_dim*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(channel_dim*2)\n",
        "        self.conv3 = nn.Conv2d(channel_dim*2, channel_dim*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(channel_dim*4)\n",
        "        self.conv4 = nn.Conv2d(channel_dim*4, channel_dim*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(channel_dim*8)\n",
        "        self.conv5 = nn.Conv2d(channel_dim*8, 1, 4, 1, 0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "RbNu0gGkLRJR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.2 Build Generator and Discriminator model\n"
      ],
      "metadata": {
        "id": "rRSt0JdcLY_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator and Discriminator\n",
        "channel_dim = 128\n",
        "latent_dim = 256\n",
        "output_dim = 1\n",
        "\n",
        "generator = Generator(latent_dim = latent_dim, channel_dim = channel_dim, output_dim = output_dim)\n",
        "discriminator = Discriminator(channel_dim = channel_dim)\n",
        "\n",
        "# Use GPU or CPU\n",
        "use_gpu = True\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)"
      ],
      "metadata": {
        "id": "NNgCU93RLYpo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.3 Check model parameters\n"
      ],
      "metadata": {
        "id": "Ck1p8hzPLd11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
        "num_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "print('Number of parameters for generator: %d and discriminator: %d' % (num_params_gen, num_params_disc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhD8pRAWLdPY",
        "outputId": "d8000f72-20ce-4457-efbc-93d21186622f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters for generator: 15212161 and discriminator: 11033985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.4 Weight initialization function\n"
      ],
      "metadata": {
        "id": "8s9uS6UiLiEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on Generator and Discriminator\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "RR5gdgGsLhGr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.5 Apply weight initialization on Generator and Discriminator\n"
      ],
      "metadata": {
        "id": "NuWqtlHNLlYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uI8cz5gLk1g",
        "outputId": "901a70d3-3b8d-4a7d-c1bc-3f3226ff3b05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv4_bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3.6 Loss function and Optimizer\n"
      ],
      "metadata": {
        "id": "CcYsEF63LoZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-5\n",
        "criterion = nn.BCELoss()\n",
        "gen_optimizer = torch.optim.AdamW(params=generator.parameters(), lr=learning_rate)\n",
        "disc_optimizer = torch.optim.AdamW(params=discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.9))"
      ],
      "metadata": {
        "id": "NvKxFopVLnnV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train DCGAN"
      ],
      "metadata": {
        "id": "ia0UuIYYLtdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4.1 Fix latent noise for visualization\n"
      ],
      "metadata": {
        "id": "d6dVbNPHLv28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn(64, latent_dim, 1, 1, device = device)\n"
      ],
      "metadata": {
        "id": "6C2CgqriLxxU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 4.2 Train Generator and Discriminator over training dataset\n"
      ],
      "metadata": {
        "id": "X2FvEILVLv5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# set to training mode\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "\n",
        "gen_losses = []\n",
        "disc_losses = []\n",
        "img_list = []\n",
        "iters = 0\n",
        "\n",
        "print('Training ...')\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for i, (image_batch, _) in enumerate(train_dataloader):\n",
        "\n",
        "        # get dataset image and create real and fake labels for use in the loss\n",
        "        image_batch = image_batch.to(device)\n",
        "        label_real = torch.ones(image_batch.size(0), device=device)\n",
        "        label_fake = torch.zeros(image_batch.size(0), device=device)\n",
        "\n",
        "        # generate a batch of images from samples of the latent prior\n",
        "        latent = torch.randn(image_batch.size(0), latent_dim, 1, 1, device=device)\n",
        "        fake_image_batch = generator(latent)\n",
        "\n",
        "        # train discriminator to correctly classify real and fake\n",
        "        # (detach the computation graph of the generator and the discriminator,\n",
        "        # so that gradients are not backpropagated into the generator)\n",
        "        real_pred = discriminator(image_batch).squeeze()\n",
        "        fake_pred = discriminator(fake_image_batch.detach()).squeeze()\n",
        "        disc_loss = 0.5 * (\n",
        "            criterion(real_pred, label_real) +\n",
        "            criterion(fake_pred, label_fake))\n",
        "\n",
        "        disc_optimizer.zero_grad()\n",
        "        disc_loss.backward()\n",
        "        disc_optimizer.step()\n",
        "\n",
        "        # train generator to output an image that is classified as real\n",
        "        fake_pred = discriminator(fake_image_batch).squeeze()\n",
        "        gen_loss = criterion(fake_pred, label_real)\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        #gen_loss_avg[-1] += gen_loss.item()\n",
        "        #disc_loss_avg[-1] += disc_loss.item()\n",
        "        #num_batches += 1\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
        "                  % (epoch, num_epochs, i, len(train_dataloader),\n",
        "                     disc_loss.item(), gen_loss.item()))\n",
        "\n",
        "        # Save losses for plotting\n",
        "        gen_losses.append(gen_loss.item())\n",
        "        disc_losses.append(disc_loss.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed noise\n",
        "        if iters % 500 == 0 or (epoch == num_epochs-1):\n",
        "            with torch.no_grad():\n",
        "                fake = generator(fixed_noise).detach().cpu()\n",
        "            img_list.append(vtils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "iUsRrqFyL08O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Visualizing Training Results\n"
      ],
      "metadata": {
        "id": "-gGsFj3qLv71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5.1 Loss vs. training iteration\n"
      ],
      "metadata": {
        "id": "e31fn2dEL5pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(gen_losses,label=\"G\")\n",
        "plt.plot(disc_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yrpprWryLs-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5.2 Visualization of Generator output\n"
      ],
      "metadata": {
        "id": "_F67NKvWL75B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.eval()\n",
        "\n",
        "# Sample random noise\n",
        "random_noise = torch.randn(64, latent_dim, 1, 1, device = device)\n",
        "\n",
        "# Generate image using Generator\n",
        "fake_image = generator(random_noise).detach().cpu()\n",
        "fake_image = vtils.make_grid(fake_image, padding=2, normalize=True)\n",
        "\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(fake_image, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pse4-JESL7ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5.3 Real Images vs. Generated Images\n"
      ],
      "metadata": {
        "id": "Jgxp3MNfMBqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(train_dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vtils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "woHuSVFEMALS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 5.4 Interpolation in latent space\n"
      ],
      "metadata": {
        "id": "ZMuPI0D6MFkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    return x\n",
        "\n",
        "def show_image(img):\n",
        "    img = to_img(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "def interpolation(lambda1, model, latent_1, latent_2):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # interpolation of the two latent vectors\n",
        "        inter_latent = lambda1* latent_1 + (1- lambda1) * latent_2\n",
        "\n",
        "        # reconstruct interpolated image\n",
        "        inter_latent = inter_latent.to(device)\n",
        "        inter_image = model(inter_latent)\n",
        "        inter_image = inter_image.cpu()\n",
        "\n",
        "        return inter_image"
      ],
      "metadata": {
        "id": "RpoY7bdlMEC7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.ion()\n",
        "generator.eval()\n",
        "\n",
        "# sample two latent vectors from the standard normal distribution\n",
        "latent_1 = torch.randn(1, latent_dim, 1, 1, device=device)\n",
        "latent_2 = torch.randn(1, latent_dim, 1, 1, device=device)\n",
        "\n",
        "# interpolation lambdas\n",
        "lambda_range=np.linspace(0,1,10)\n",
        "\n",
        "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "\n",
        "for ind,l in enumerate(lambda_range):\n",
        "    inter_image = interpolation(float(l), generator, latent_1, latent_2)\n",
        "\n",
        "    inter_image = to_img(inter_image)\n",
        "\n",
        "    image = inter_image.numpy()\n",
        "\n",
        "    axs[ind].imshow(image[0,0,:,:], cmap='gray')\n",
        "    axs[ind].set_title('lambda_val='+str(round(l,1)))\n",
        "    axs[ind].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7wapFHaCMH94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}