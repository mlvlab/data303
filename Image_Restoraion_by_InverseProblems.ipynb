{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlvlab/data303/blob/main/Image_Restoraion_by_InverseProblems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d10a32-4134-4539-9f06-a44efd6c4f00",
      "metadata": {
        "id": "08d10a32-4134-4539-9f06-a44efd6c4f00"
      },
      "source": [
        "# 0. Download git repo and Prepare requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "83e77df0-4ebb-4241-93ee-43ade99c011d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83e77df0-4ebb-4241-93ee-43ade99c011d",
        "outputId": "1ad6a93e-62e2-4879-d0fc-f7c5564740e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DDNM'...\n",
            "remote: Enumerating objects: 607, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 607 (delta 156), reused 68 (delta 68), pack-reused 423\u001b[K\n",
            "Receiving objects: 100% (607/607), 14.30 MiB | 17.12 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wyhuai/DDNM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "06ac6f4b-4bc4-425f-9c2c-353f3db243d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ac6f4b-4bc4-425f-9c2c-353f3db243d2",
        "outputId": "35f5de4e-d455-4c5e-8adf-d654d6b7925a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DDNM\n"
          ]
        }
      ],
      "source": [
        "cd DDNM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f6543698-5838-448e-8617-0991c2f759e2",
      "metadata": {
        "tags": [],
        "id": "f6543698-5838-448e-8617-0991c2f759e2"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import traceback\n",
        "import shutil\n",
        "import logging\n",
        "import yaml\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.utils.tensorboard as tb\n",
        "import random\n",
        "import torchvision.utils as tvu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abf82ce-66ef-4f65-96c5-443a4da087d4",
      "metadata": {
        "tags": [],
        "id": "9abf82ce-66ef-4f65-96c5-443a4da087d4"
      },
      "outputs": [],
      "source": [
        "def dict2namespace(config):\n",
        "    namespace = argparse.Namespace()\n",
        "    for key, value in config.items():\n",
        "        if isinstance(value, dict):\n",
        "            new_value = dict2namespace(value)\n",
        "        else:\n",
        "            new_value = value\n",
        "        setattr(namespace, key, new_value)\n",
        "    return namespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd280c3-5f77-4277-8760-ae20079c6b95",
      "metadata": {
        "tags": [],
        "id": "5dd280c3-5f77-4277-8760-ae20079c6b95"
      },
      "outputs": [],
      "source": [
        "def parse_args_and_config(args):\n",
        "\n",
        "    config = ''\n",
        "    # parse config file\n",
        "    with open(os.path.join(\"configs\", args.config), \"r\") as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    new_config = dict2namespace(config)\n",
        "\n",
        "    if 'dataset' in config['data'].keys():\n",
        "        dataset_name = config['data']['dataset']\n",
        "    elif 'name' in config['data'].keys():\n",
        "        dataset_name = config['data']['name']\n",
        "\n",
        "\n",
        "    time_info = 'Tsample{}_len{}_repeat{}'.format(args.T_sampling, args.travel_length, args.travel_repeat)\n",
        "\n",
        "    args.new_image_folder = os.path.join(args.image_folder, f'{dataset_name}_{args.deg}/{time_info}/eta{args.eta}_etaB{args.etaB}_sigmay{args.sigma_y}')\n",
        "    new_config.deg = args.deg\n",
        "\n",
        "    level = getattr(logging, args.verbose.upper(), None)\n",
        "    if not isinstance(level, int):\n",
        "        raise ValueError(\"level {} not supported\".format(args.verbose))\n",
        "\n",
        "    handler1 = logging.StreamHandler()\n",
        "    formatter = logging.Formatter(\n",
        "        \"%(levelname)s - %(filename)s - %(asctime)s - %(message)s\"\n",
        "    )\n",
        "    handler1.setFormatter(formatter)\n",
        "    logger = logging.getLogger()\n",
        "    logger.addHandler(handler1)\n",
        "    logger.setLevel(level)\n",
        "\n",
        "\n",
        "    if not os.path.exists(args.new_image_folder):\n",
        "        os.makedirs(args.new_image_folder)\n",
        "\n",
        "    # add device\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    logging.info(\"Using device: {}\".format(device))\n",
        "    new_config.device = device\n",
        "    args.device = device\n",
        "\n",
        "    # set random seed\n",
        "    torch.manual_seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    return args, new_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fa6157-28f5-49c8-8c9d-ed4e8493a944",
      "metadata": {
        "tags": [],
        "id": "b4fa6157-28f5-49c8-8c9d-ed4e8493a944"
      },
      "outputs": [],
      "source": [
        "def logit_transform(image, lam=1e-6):\n",
        "    image = lam + (1 - 2 * lam) * image\n",
        "    return torch.log(image) - torch.log1p(-image)\n",
        "\n",
        "def compute_alpha(beta, t):\n",
        "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
        "    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)\n",
        "    return a\n",
        "\n",
        "def data_transform(config, X):\n",
        "    if config.data.uniform_dequantization:\n",
        "        X = X / 256.0 * 255.0 + torch.rand_like(X) / 256.0\n",
        "    if config.data.gaussian_dequantization:\n",
        "        X = X + torch.randn_like(X) * 0.01\n",
        "\n",
        "    if config.data.rescaled:\n",
        "        X = 2 * X - 1.0\n",
        "    elif config.data.logit_transform:\n",
        "        X = logit_transform(X)\n",
        "\n",
        "    if hasattr(config, \"image_mean\"):\n",
        "        return X - config.image_mean.to(X.device)[None, ...]\n",
        "\n",
        "    return X\n",
        "\n",
        "def inverse_data_transform(x):\n",
        "    x = (x + 1.0) / 2.0\n",
        "    return torch.clamp(x, 0.0, 1.0)\n",
        "\n",
        "def inverse_data_transform_config(config, X):\n",
        "    if hasattr(config, \"image_mean\"):\n",
        "        X = X + config.image_mean.to(X.device)[None, ...]\n",
        "\n",
        "    if config.data.logit_transform:\n",
        "        X = torch.sigmoid(X)\n",
        "    elif config.data.rescaled:\n",
        "        X = (X + 1.0) / 2.0\n",
        "    return torch.clamp(X, 0.0, 1.0)\n",
        "\n",
        "def _check_times(times, t_0, T_sampling):\n",
        "    # Check end\n",
        "    assert times[0] > times[1], (times[0], times[1])\n",
        "\n",
        "    # Check beginning\n",
        "    assert times[-1] == -1, times[-1]\n",
        "\n",
        "    # Steplength = 1\n",
        "    for t_last, t_cur in zip(times[:-1], times[1:]):\n",
        "        assert abs(t_last - t_cur) == 1, (t_last, t_cur)\n",
        "\n",
        "    # Value range\n",
        "    for t in times:\n",
        "        assert t >= t_0, (t, t_0)\n",
        "        assert t <= T_sampling, (t, T_sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61ae70a-fe40-4624-a63b-38a452ab6f7f",
      "metadata": {
        "tags": [],
        "id": "a61ae70a-fe40-4624-a63b-38a452ab6f7f"
      },
      "outputs": [],
      "source": [
        "def get_gaussian_noisy_img(img, noise_level):\n",
        "    return img + torch.randn_like(img).cuda() * noise_level\n",
        "\n",
        "def MeanUpsample(x, scale):\n",
        "    n, c, h, w = x.shape\n",
        "    out = torch.zeros(n, c, h, scale, w, scale).to(x.device) + x.view(n,c,h,1,w,1)\n",
        "    out = out.view(n, c, scale*h, scale*w)\n",
        "    return out\n",
        "\n",
        "def color2gray(x):\n",
        "    coef=1/3\n",
        "    x = x[:,0,:,:] * coef + x[:,1,:,:]*coef +  x[:,2,:,:]*coef\n",
        "    return x.repeat(1,3,1,1)\n",
        "\n",
        "def gray2color(x):\n",
        "    x = x[:,0,:,:]\n",
        "    coef=1/3\n",
        "    base = coef**2 + coef**2 + coef**2\n",
        "    return torch.stack((x*coef/base, x*coef/base, x*coef/base), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "235b57c9-94e1-487d-8948-57567db60cab",
      "metadata": {
        "id": "235b57c9-94e1-487d-8948-57567db60cab"
      },
      "source": [
        "# 1. Define Diffusion Process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0fbab6-6c91-430a-aa0b-fb47bc01e31d",
      "metadata": {
        "id": "1c0fbab6-6c91-430a-aa0b-fb47bc01e31d"
      },
      "source": [
        "## 1-1. Noise scheduling function\n",
        "* Linear - DDPM scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "067c7b08-c1c2-4bab-b4e7-49b2cb343176",
      "metadata": {
        "tags": [],
        "id": "067c7b08-c1c2-4bab-b4e7-49b2cb343176"
      },
      "outputs": [],
      "source": [
        "def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n",
        "    def sigmoid(x):\n",
        "        return 1 / (np.exp(-x) + 1)\n",
        "\n",
        "    if beta_schedule == \"quad\":\n",
        "        betas = (\n",
        "            np.linspace(\n",
        "                beta_start ** 0.5,\n",
        "                beta_end ** 0.5,\n",
        "                num_diffusion_timesteps,\n",
        "                dtype=np.float64,\n",
        "            )\n",
        "            ** 2\n",
        "        )\n",
        "    elif beta_schedule == \"linear\":\n",
        "        betas = np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"const\":\n",
        "        betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n",
        "    elif beta_schedule == \"jsd\":\n",
        "        betas = 1.0 / np.linspace(\n",
        "            num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"sigmoid\":\n",
        "        betas = np.linspace(-6, 6, num_diffusion_timesteps)\n",
        "        betas = sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
        "    else:\n",
        "        raise NotImplementedError(beta_schedule)\n",
        "    assert betas.shape == (num_diffusion_timesteps,)\n",
        "    return betas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0070b2a-ed0b-4085-8a2d-4c84b3388049",
      "metadata": {
        "id": "e0070b2a-ed0b-4085-8a2d-4c84b3388049"
      },
      "source": [
        "## 1-2. Class Diffusion\n",
        "* Sample function: Download pretrained weight and Run DDNM algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77231f21-15bc-462d-b182-21e02c28559b",
      "metadata": {
        "tags": [],
        "id": "77231f21-15bc-462d-b182-21e02c28559b"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "import tqdm\n",
        "from datasets import get_dataset, data_transform, inverse_data_transform\n",
        "from guided_diffusion.models import Model\n",
        "from guided_diffusion.script_util import create_model\n",
        "from functions.ckpt_util import get_ckpt_path, download\n",
        "\n",
        "class Diffusion(object):\n",
        "    def __init__(self, args, config, device=None):\n",
        "        self.args = args\n",
        "        self.config = config\n",
        "        if device is None:\n",
        "            device = (torch.device(\"cuda\") if torch.cuda.is_available()\n",
        "                      else torch.device(\"cpu\"))\n",
        "        self.device = device\n",
        "\n",
        "        self.model_var_type = config.model.var_type\n",
        "        betas = get_beta_schedule(\n",
        "            beta_schedule=config.diffusion.beta_schedule,\n",
        "            beta_start=config.diffusion.beta_start,\n",
        "            beta_end=config.diffusion.beta_end,\n",
        "            num_diffusion_timesteps=config.diffusion.num_diffusion_timesteps,\n",
        "        )\n",
        "        betas = self.betas = torch.from_numpy(betas).float().to(self.device)\n",
        "        self.num_timesteps = betas.shape[0]\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cumprod = alphas.cumprod(dim=0)\n",
        "        alphas_cumprod_prev = torch.cat(\n",
        "            [torch.ones(1).to(device), alphas_cumprod[:-1]], dim=0\n",
        "        )\n",
        "        self.alphas_cumprod_prev = alphas_cumprod_prev\n",
        "        posterior_variance = (\n",
        "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "        )\n",
        "        if self.model_var_type == \"fixedlarge\":\n",
        "            self.logvar = betas.log()\n",
        "        elif self.model_var_type == \"fixedsmall\":\n",
        "            self.logvar = posterior_variance.clamp(min=1e-20).log()\n",
        "\n",
        "\n",
        "    def sample(self, A_funcs):\n",
        "        cls_fn = None\n",
        "\n",
        "        # Download Pretrained model checkpoint\n",
        "        if self.config.model.type == 'openai':\n",
        "            config_dict = vars(self.config.model)\n",
        "            model = create_model(**config_dict)\n",
        "            if self.config.model.use_fp16:\n",
        "                model.convert_to_fp16()\n",
        "\n",
        "            ckpt = os.path.join(self.args.exp, \"logs/imagenet/256x256_diffusion_uncond.pt\")\n",
        "            if not os.path.exists(ckpt):\n",
        "                download(\n",
        "                    'https://openaipublic.blob.core.windows.net/diffusion/jul-2021/256x256_diffusion_uncond.pt',\n",
        "                    ckpt)\n",
        "\n",
        "            model.load_state_dict(torch.load(ckpt, map_location=self.device))\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "            model = torch.nn.DataParallel(model)\n",
        "\n",
        "\n",
        "        print('Run SVD-based DDNM.',\n",
        "              f'{self.config.time_travel.T_sampling} sampling steps.',\n",
        "              f'travel_length = {self.config.time_travel.travel_length},',\n",
        "              f'travel_repeat = {self.config.time_travel.travel_repeat}.',\n",
        "              f'Task: {self.args.deg}.'\n",
        "             )\n",
        "        self.svd_based_ddnm_plus(model, cls_fn, A_funcs)\n",
        "\n",
        "\n",
        "\n",
        "    def svd_based_ddnm_plus(self, model, cls_fn, A_funcs):\n",
        "        args, config = self.args, self.config\n",
        "\n",
        "        dataset, test_dataset = get_dataset(args, config)\n",
        "        device_count = torch.cuda.device_count()\n",
        "\n",
        "        if args.subset_start >= 0 and args.subset_end > 0:\n",
        "            assert args.subset_end > args.subset_start\n",
        "            test_dataset = torch.utils.data.Subset(test_dataset, range(args.subset_start, args.subset_end))\n",
        "        else:\n",
        "            args.subset_start = 0\n",
        "            args.subset_end = len(test_dataset)\n",
        "\n",
        "        print(f'Dataset has size {len(test_dataset)}')\n",
        "\n",
        "        def seed_worker(worker_id):\n",
        "            worker_seed = args.seed % 2 ** 32\n",
        "            np.random.seed(worker_seed)\n",
        "            random.seed(worker_seed)\n",
        "\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(args.seed)\n",
        "        val_loader = data.DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=config.sampling.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=config.data.num_workers,\n",
        "            worker_init_fn=seed_worker,\n",
        "            generator=g,\n",
        "        )\n",
        "\n",
        "        deg = args.deg\n",
        "        args.sigma_y = 2 * args.sigma_y #to account for scaling to [-1,1]\n",
        "        sigma_y = args.sigma_y\n",
        "\n",
        "        print(f'Start from {args.subset_start}')\n",
        "        idx_init = args.subset_start\n",
        "        idx_so_far = args.subset_start\n",
        "        avg_psnr = 0.0\n",
        "        pbar = tqdm.tqdm(val_loader)\n",
        "        for x_orig, classes in pbar:\n",
        "            x_orig = x_orig.to(self.device)\n",
        "            x_orig = data_transform(self.config, x_orig)\n",
        "\n",
        "            y = A_funcs.A(x_orig)\n",
        "\n",
        "            b, hwc = y.size()\n",
        "            if 'color' in deg:\n",
        "                hw = hwc / 1\n",
        "                h = w = int(hw ** 0.5)\n",
        "                y = y.reshape((b, 1, h, w))\n",
        "            elif 'inp' in deg or 'cs' in deg:\n",
        "                pass\n",
        "            else:\n",
        "                hw = hwc / 3\n",
        "                h = w = int(hw ** 0.5)\n",
        "                y = y.reshape((b, 3, h, w))\n",
        "\n",
        "            if self.args.add_noise: # for denoising test\n",
        "                y = get_gaussian_noisy_img(y, sigma_y)\n",
        "\n",
        "            y = y.reshape((b, hwc))\n",
        "\n",
        "            Apy = A_funcs.A_pinv(y).view(y.shape[0], config.data.channels, self.config.data.image_size,\n",
        "                                                self.config.data.image_size)\n",
        "\n",
        "            if deg[:6] == 'deblur':\n",
        "                Apy = y.view(y.shape[0], config.data.channels, self.config.data.image_size,\n",
        "                                    self.config.data.image_size)\n",
        "            elif deg == 'colorization':\n",
        "                Apy = y.view(y.shape[0], 1, self.config.data.image_size, self.config.data.image_size).repeat(1,3,1,1)\n",
        "            elif deg == 'inpainting':\n",
        "                Apy += A_funcs.A_pinv(A_funcs.A(torch.ones_like(Apy))).reshape(*Apy.shape) - 1\n",
        "\n",
        "            for i in range(len(Apy)):\n",
        "                tvu.save_image(\n",
        "                    inverse_data_transform_config(config, Apy[i]),\n",
        "                    os.path.join(self.args.new_image_folder, f\"degradation-{idx_so_far + i}.png\")\n",
        "                )\n",
        "                tvu.save_image(\n",
        "                    inverse_data_transform_config(config, x_orig[i]),\n",
        "                    os.path.join(self.args.new_image_folder, f\"gt-{idx_so_far + i}.png\")\n",
        "                )\n",
        "\n",
        "            #Start DDIM\n",
        "            x = torch.randn(\n",
        "                y.shape[0],\n",
        "                config.data.channels,\n",
        "                config.data.image_size,\n",
        "                config.data.image_size,\n",
        "                device=self.device,\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if sigma_y==0.: # noise-free case, turn to ddnm\n",
        "                    x, _ = ddnm_diffusion(x, model, self.betas, self.args.eta, A_funcs, y, args.device, cls_fn=cls_fn, classes=classes, config=config)\n",
        "                else: # noisy case, turn to ddnm+\n",
        "                    from functions.svd_ddnm import ddnm_plus_diffusion\n",
        "                    x, _ = ddnm_plus_diffusion(x, model, self.betas, self.args.eta, A_funcs, y, sigma_y, args.device, cls_fn=cls_fn, classes=classes, config=config)\n",
        "\n",
        "            x = [inverse_data_transform_config(config, xi) for xi in x]\n",
        "\n",
        "            for j in range(x[0].size(0)):\n",
        "                tvu.save_image(\n",
        "                    x[0][j], os.path.join(self.args.new_image_folder, f\"recon-{idx_so_far + j}_{0}.png\")\n",
        "                )\n",
        "                orig = inverse_data_transform_config(config, x_orig[j])\n",
        "                mse = torch.mean((x[0][j].to(self.device) - orig) ** 2)\n",
        "                psnr = 10 * torch.log10(1 / mse)\n",
        "                avg_psnr += psnr\n",
        "\n",
        "            idx_so_far += y.shape[0]\n",
        "\n",
        "            pbar.set_description(\"PSNR: %.2f\" % (avg_psnr / (idx_so_far - idx_init)))\n",
        "\n",
        "        avg_psnr = avg_psnr / (idx_so_far - idx_init)\n",
        "        print(\"Total Average PSNR: %.2f\" % avg_psnr)\n",
        "        print(\"Number of samples: %d\" % (idx_so_far - idx_init))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2641572-b8c4-4534-821a-9c41216149b6",
      "metadata": {
        "tags": [],
        "id": "b2641572-b8c4-4534-821a-9c41216149b6"
      },
      "outputs": [],
      "source": [
        "def get_schedule_jump(T_sampling, travel_length, travel_repeat):\n",
        "\n",
        "    jumps = {}\n",
        "    for j in range(0, T_sampling - travel_length, travel_length):\n",
        "        jumps[j] = travel_repeat - 1\n",
        "\n",
        "    t = T_sampling\n",
        "    ts = []\n",
        "\n",
        "    while t >= 1:\n",
        "        t = t-1\n",
        "        ts.append(t)\n",
        "\n",
        "        if jumps.get(t, 0) > 0:\n",
        "            jumps[t] = jumps[t] - 1\n",
        "            for _ in range(travel_length):\n",
        "                t = t + 1\n",
        "                ts.append(t)\n",
        "\n",
        "    ts.append(-1)\n",
        "\n",
        "    _check_times(ts, -1, T_sampling)\n",
        "\n",
        "    return ts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78322495-e3d2-42cb-8b60-8d2f91ee9a56",
      "metadata": {
        "id": "78322495-e3d2-42cb-8b60-8d2f91ee9a56"
      },
      "source": [
        "# 2.DDNM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea12f26-6853-47e0-a6e8-9bc04a743321",
      "metadata": {
        "tags": [],
        "id": "eea12f26-6853-47e0-a6e8-9bc04a743321"
      },
      "outputs": [],
      "source": [
        "def ddnm_diffusion(x, model, b, eta, A_funcs, y, device, cls_fn=None, classes=None, config=None):\n",
        "    with torch.no_grad():\n",
        "        # setup iteration variables\n",
        "        skip = config.diffusion.num_diffusion_timesteps//config.time_travel.T_sampling\n",
        "        n = x.size(0)\n",
        "        x0_preds = []\n",
        "        xs = [x]\n",
        "\n",
        "        # generate time schedule\n",
        "        times = get_schedule_jump(config.time_travel.T_sampling,\n",
        "                               config.time_travel.travel_length,\n",
        "                               config.time_travel.travel_repeat,\n",
        "                              )\n",
        "        time_pairs = list(zip(times[:-1], times[1:]))\n",
        "\n",
        "        # reverse diffusion sampling\n",
        "        for i, j in tqdm.tqdm(time_pairs):\n",
        "            i, j = i*skip, j*skip\n",
        "            if j<0:\n",
        "              j=-1\n",
        "\n",
        "            if j < i: # normal sampling\n",
        "                t = (torch.ones(n) * i).to(x.device)\n",
        "                next_t = (torch.ones(n) * j).to(x.device)\n",
        "                at = compute_alpha(b, t.long())\n",
        "                at_next = compute_alpha(b, next_t.long())\n",
        "\n",
        "                xt = xs[-1].to(device)\n",
        "                et = model(xt, t)\n",
        "\n",
        "                if et.size(1) == 6:\n",
        "                    et = et[:, :3]\n",
        "\n",
        "                x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
        "\n",
        "                x0_t_hat = x0_t - A_funcs.A_pinv(\n",
        "                    A_funcs.A(x0_t.reshape(x0_t.size(0), -1)) - y.reshape(y.size(0), -1)\n",
        "                ).reshape(*x0_t.size())\n",
        "\n",
        "                c1 = (1 - at_next).sqrt() * eta\n",
        "                c2 = (1 - at_next).sqrt() * ((1 - eta ** 2) ** 0.5)\n",
        "                xt_next = at_next.sqrt() * x0_t_hat + c1 * torch.randn_like(x0_t) + c2 * et\n",
        "\n",
        "                x0_preds.append(x0_t.to('cpu'))\n",
        "                xs.append(xt_next.to('cpu'))\n",
        "\n",
        "            else: # time-travel back\n",
        "                next_t = (torch.ones(n) * j).to(x.device)\n",
        "                at_next = compute_alpha(b, next_t.long())\n",
        "\n",
        "                x0_t = x0_preds[-1].to(device)\n",
        "\n",
        "                xt_next = at_next.sqrt() * x0_t + torch.randn_like(x0_t) * (1 - at_next).sqrt()\n",
        "\n",
        "                xs.append(xt_next.to('cpu'))\n",
        "\n",
        "    return [xs[-1]], [x0_preds[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Degradation Operators"
      ],
      "metadata": {
        "id": "FB4D1AUFqOVV"
      },
      "id": "FB4D1AUFqOVV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "debfb2bd-4070-44ba-8116-5bbd8267937f",
      "metadata": {
        "tags": [],
        "id": "debfb2bd-4070-44ba-8116-5bbd8267937f"
      },
      "outputs": [],
      "source": [
        "def get_degradation_matrix(deg, device, deg_scale=4):\n",
        "    A_funcs = None\n",
        "\n",
        "    if deg == 'inpainting':\n",
        "        from functions.svd_operators import Inpainting\n",
        "        loaded = np.load(\"exp/inp_masks/mask.npy\")\n",
        "        mask = torch.from_numpy(loaded).to(device).reshape(-1)\n",
        "        missing_r = torch.nonzero(mask == 0).long().reshape(-1) * 3\n",
        "        missing_g = missing_r + 1\n",
        "        missing_b = missing_g + 1\n",
        "        missing = torch.cat([missing_r, missing_g, missing_b], dim=0)\n",
        "        A_funcs = Inpainting(3, 256, missing, device)\n",
        "    elif deg == 'colorization':\n",
        "        from functions.svd_operators import Colorization\n",
        "        A_funcs = Colorization(256, device)\n",
        "    elif deg == 'sr_averagepooling':\n",
        "        blur_by = int(args.deg_scale)\n",
        "        from functions.svd_operators import SuperResolution\n",
        "        A_funcs = SuperResolution(3, 256, blur_by, device)\n",
        "    elif deg == 'sr_bicubic':\n",
        "        factor = int(args.deg_scale)\n",
        "        from functions.svd_operators import SRConv\n",
        "        def bicubic_kernel(x, a=-0.5):\n",
        "            if abs(x) <= 1:\n",
        "                return (a + 2) * abs(x) ** 3 - (a + 3) * abs(x) ** 2 + 1\n",
        "            elif 1 < abs(x) and abs(x) < 2:\n",
        "                return a * abs(x) ** 3 - 5 * a * abs(x) ** 2 + 8 * a * abs(x) - 4 * a\n",
        "            else:\n",
        "                return 0\n",
        "        k = np.zeros((factor * 4))\n",
        "        for i in range(factor * 4):\n",
        "            x = (1 / factor) * (i - np.floor(factor * 4 / 2) + 0.5)\n",
        "            k[i] = bicubic_kernel(x)\n",
        "        k = k / np.sum(k)\n",
        "        kernel = torch.from_numpy(k).float().to(device)\n",
        "        A_funcs = SRConv(kernel / kernel.sum(), \\\n",
        "                         3, 256, device, stride=factor)\n",
        "    elif deg == 'deblur_gauss':\n",
        "        from functions.svd_operators import Deblurring\n",
        "        sigma = 10\n",
        "        pdf = lambda x: torch.exp(torch.Tensor([-0.5 * (x / sigma) ** 2]))\n",
        "        kernel = torch.Tensor([pdf(-2), pdf(-1), pdf(0), pdf(1), pdf(2)]).to(device)\n",
        "        A_funcs = Deblurring(kernel / kernel.sum(), 3, 256, device)\n",
        "    else:\n",
        "        raise ValueError(\"degradation type not supported\")\n",
        "\n",
        "    return A_funcs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Main"
      ],
      "metadata": {
        "id": "wTntr3djq2mb"
      },
      "id": "wTntr3djq2mb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec897af-7edd-4e9a-9b4b-c230010c2e7a",
      "metadata": {
        "tags": [],
        "id": "8ec897af-7edd-4e9a-9b4b-c230010c2e7a"
      },
      "outputs": [],
      "source": [
        "def colab_main(args):\n",
        "    input_args, config = parse_args_and_config(args)\n",
        "\n",
        "    try:\n",
        "      runner = Diffusion(input_args, config)\n",
        "      A_funcs = get_degradation_matrix(input_args.deg, input_args.device)\n",
        "      runner.sample(A_funcs)\n",
        "    except Exception:\n",
        "      logging.error(traceback.format_exc())\n",
        "\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Degradation types and Images"
      ],
      "metadata": {
        "id": "VG1g4WWYq5j-"
      },
      "id": "VG1g4WWYq5j-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f93a290-87f8-4bdf-8700-c1df8a60aedf",
      "metadata": {
        "tags": [],
        "id": "6f93a290-87f8-4bdf-8700-c1df8a60aedf"
      },
      "outputs": [],
      "source": [
        "from easydict import EasyDict\n",
        "\n",
        "args = EasyDict()\n",
        "args.image_folder = '../results'\n",
        "args.config = 'imagenet_256.yml'\n",
        "args.path_y = 'imagenet'\n",
        "args.simplified = False\n",
        "args.seed = 1234\n",
        "args.exp = 'exp'\n",
        "args.verbose = 'info'\n",
        "\n",
        "args.sigma_y = 0\n",
        "args.eta = 0.85\n",
        "args.cutoff = 1000\n",
        "args.etaB = 1\n",
        "args.noise_type = 'gaussian'\n",
        "args.add_noise = False\n",
        "\n",
        "# (Optional) Set sampling timesteps and Time travel steps\n",
        "# Time travel was not covered in theory classes.\n",
        "args.timesteps = 1000\n",
        "args.T_sampling = 100\n",
        "args.travel_length = 1\n",
        "args.travel_repeat = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Edit this block as you want.\"\n",
        "\n",
        "* Degradaton typs: sr_averagepooling, colorization, inpainting, sr_bicubic, deblur_gauss"
      ],
      "metadata": {
        "id": "JLFLF1OnsYXL"
      },
      "id": "JLFLF1OnsYXL"
    },
    {
      "cell_type": "code",
      "source": [
        "'''Select Degradation types'''\n",
        "args.deg = 'sr_averagepooling'\n",
        "# args.deg = 'colorization'\n",
        "# args.deg = 'inpainting'\n",
        "# args.deg = 'sr_bicubic'\n",
        "# args.deg = 'deblur_gauss'\n",
        "\n",
        "# For Super-resolution, set degraded scale\n",
        "args.deg_scale = 4 # 8, 16\n",
        "\n",
        "'''\n",
        "Select Images\n",
        "Colab stops if all 8 images are inferred at once.\n",
        "Do 1 or 2 at once.\n",
        "DDNM/exp/datasets/imagenet/imagenet - 8 images exist\n",
        "'''\n",
        "args.subset_start = 0 # start idx >= 0\n",
        "args.subset_end = 2 # start idx < end idx <= 8"
      ],
      "metadata": {
        "id": "RjWhLYdjsWgs"
      },
      "id": "RjWhLYdjsWgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a78845-78ba-4ed7-b6da-ac34d15590e2",
      "metadata": {
        "id": "87a78845-78ba-4ed7-b6da-ac34d15590e2"
      },
      "outputs": [],
      "source": [
        "colab_main(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876db295-6313-4a49-8fc1-917fc9fdc388",
      "metadata": {
        "id": "876db295-6313-4a49-8fc1-917fc9fdc388"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}